{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c64464af",
   "metadata": {},
   "source": [
    "**Intengrates del equipo:** \n",
    "\n",
    "Oscar Ivan Echeverria Marrugo\n",
    "\n",
    "Fabian AndrÃ©s Parrado VelÃ¡squez\n",
    "\n",
    "Xiomara Grisales Henao \n",
    "\n",
    "Javier Callejas Cardozo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72922b8",
   "metadata": {},
   "source": [
    "\n",
    "# Actividad 1: Preprocesamiento y TokenizaciÃ³n\n",
    "---\n",
    "En esta actividad, realizaremos los siguientes pasos:\n",
    "\n",
    "1. Cargar el archivo de datos de noticias.\n",
    "2. Realizar el preprocesamiento del texto, que incluye:\n",
    "   - Convertir el texto a minÃºsculas.\n",
    "   - Eliminar puntuaciÃ³n.\n",
    "   - Eliminar nÃºmeros.\n",
    "   - Eliminar espacios en blanco adicionales.\n",
    "3. Tokenizar el texto en palabras individuales.\n",
    "4. Eliminar stop words del texto tokenizado.\n",
    "5. Calcular TF-IDF para representar el texto como vectores numÃ©ricos.\n",
    "6. Generar embeddings de palabras utilizando Word2Vec.\n",
    "\n",
    "\n",
    "## LibrerÃ­as\n",
    "\n",
    "Para esta actividad, necesitaremos las siguientes librerÃ­as:\n",
    "\n",
    "- pandas: Para cargar y manipular los datos.\n",
    "- numpy: Para realizar operaciones numÃ©ricas.\n",
    "- nltk: Para realizar el preprocesamiento y tokenizaciÃ³n del texto.\n",
    "- gensim: Para generar los embeddings de palabras.\n",
    "\n",
    "Este proyecto usa Python 3.10 y usa poetry para manejar las dependencias. Para instalar las dependencias, ejecute `poetry install` en la carpeta raÃ­z del proyecto. Para mÃ¡s informaciÃ³n sobre poetry, consulte la [documentaciÃ³n oficial](https://python-poetry.org/docs/).\n",
    "\n",
    "Si no quiere usar poetry, puede instalar las dependencias manualmente usando pip:\n",
    "\n",
    "```bash\n",
    "pip install pandas numpy scikit-learn nltk gensim scipy openpyxl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f9ac65",
   "metadata": {},
   "source": [
    "### NLTK\n",
    "\n",
    "Nltk requiere que descarguemos algunos recursos adicionales. Para hacerlo, ejecute el siguiente cÃ³digo:\n",
    "\n",
    "```python\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ee605c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Columna1</th>\n",
       "      <th>Enlaces</th>\n",
       "      <th>TÃ­tulo</th>\n",
       "      <th>info</th>\n",
       "      <th>contenido</th>\n",
       "      <th>Etiqueta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://www.eltiempo.com/agresion-contra-un-op...</td>\n",
       "      <td>Operador de grÃºa quedÃ³ inconsciente tras agres...</td>\n",
       "      <td>El conductor de una moto le lanzÃ³ el casco y p...</td>\n",
       "      <td>Las autoridades estÃ¡n buscando al conductor de...</td>\n",
       "      <td>colombia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.eltiempo.com/archivo/documento/CMS...</td>\n",
       "      <td>UsaquÃ©n, primera en infracciones por mal parqueo</td>\n",
       "      <td>La localidad ocupa el primer lugar en comparen...</td>\n",
       "      <td>\"Los andenes son para los peatones\", reclama e...</td>\n",
       "      <td>archivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.eltiempo.com/archivo/documento/CMS...</td>\n",
       "      <td>'Me atracaron y vi un arma que me helÃ³ la sang...</td>\n",
       "      <td>Un ciudadano relata cÃ³mo cuatro hombres lo rob...</td>\n",
       "      <td>A las 7 de la noche me habÃ­a quedado de encont...</td>\n",
       "      <td>archivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://www.eltiempo.com/archivo/documento/CMS...</td>\n",
       "      <td>Escoltas mal estacionados, dolor de cabeza de ...</td>\n",
       "      <td>Las zonas de restaurantes se convierten en par...</td>\n",
       "      <td>Atravesados. Eso es lo que se les pasa por la ...</td>\n",
       "      <td>archivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.eltiempo.com/archivo/documento/CMS...</td>\n",
       "      <td>Radicado primer proyecto que autorizarÃ­a union...</td>\n",
       "      <td>El representante de 'la U', Miguel GÃ³mez, dijo...</td>\n",
       "      <td>â€œEstamos proponiendo la figura de un contrato ...</td>\n",
       "      <td>archivo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Columna1                                            Enlaces  \\\n",
       "0         0  https://www.eltiempo.com/agresion-contra-un-op...   \n",
       "1         1  https://www.eltiempo.com/archivo/documento/CMS...   \n",
       "2         2  https://www.eltiempo.com/archivo/documento/CMS...   \n",
       "3         3  https://www.eltiempo.com/archivo/documento/CMS...   \n",
       "4         4  https://www.eltiempo.com/archivo/documento/CMS...   \n",
       "\n",
       "                                              TÃ­tulo  \\\n",
       "0  Operador de grÃºa quedÃ³ inconsciente tras agres...   \n",
       "1   UsaquÃ©n, primera en infracciones por mal parqueo   \n",
       "2  'Me atracaron y vi un arma que me helÃ³ la sang...   \n",
       "3  Escoltas mal estacionados, dolor de cabeza de ...   \n",
       "4  Radicado primer proyecto que autorizarÃ­a union...   \n",
       "\n",
       "                                                info  \\\n",
       "0  El conductor de una moto le lanzÃ³ el casco y p...   \n",
       "1  La localidad ocupa el primer lugar en comparen...   \n",
       "2  Un ciudadano relata cÃ³mo cuatro hombres lo rob...   \n",
       "3  Las zonas de restaurantes se convierten en par...   \n",
       "4  El representante de 'la U', Miguel GÃ³mez, dijo...   \n",
       "\n",
       "                                           contenido  Etiqueta  \n",
       "0  Las autoridades estÃ¡n buscando al conductor de...  colombia  \n",
       "1  \"Los andenes son para los peatones\", reclama e...   archivo  \n",
       "2  A las 7 de la noche me habÃ­a quedado de encont...   archivo  \n",
       "3  Atravesados. Eso es lo que se les pasa por la ...   archivo  \n",
       "4  â€œEstamos proponiendo la figura de un contrato ...   archivo  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Descargar recursos de NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Cargar el archivo de datos\n",
    "file_path = '../../Datos/Datos Crudos/Noticias.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Mostrar una vista previa de los datos\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b11913e",
   "metadata": {},
   "source": [
    "## Paso 1: Preprocesamiento del Texto\n",
    "\n",
    "En este paso, transformaremos el texto a minÃºsculas, eliminaremos la puntuaciÃ³n, los nÃºmeros y los espacios en blanco adicionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f286e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contenido</th>\n",
       "      <th>contenido_preprocesado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Las autoridades estÃ¡n buscando al conductor de...</td>\n",
       "      <td>las autoridades estÃ¡n buscando al conductor de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Los andenes son para los peatones\", reclama e...</td>\n",
       "      <td>los andenes son para los peatones reclama enfÃ¡...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A las 7 de la noche me habÃ­a quedado de encont...</td>\n",
       "      <td>a las  de la noche me habÃ­a quedado de encontr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Atravesados. Eso es lo que se les pasa por la ...</td>\n",
       "      <td>atravesados eso es lo que se les pasa por la c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>â€œEstamos proponiendo la figura de un contrato ...</td>\n",
       "      <td>â€œestamos proponiendo la figura de un contrato ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           contenido  \\\n",
       "0  Las autoridades estÃ¡n buscando al conductor de...   \n",
       "1  \"Los andenes son para los peatones\", reclama e...   \n",
       "2  A las 7 de la noche me habÃ­a quedado de encont...   \n",
       "3  Atravesados. Eso es lo que se les pasa por la ...   \n",
       "4  â€œEstamos proponiendo la figura de un contrato ...   \n",
       "\n",
       "                              contenido_preprocesado  \n",
       "0  las autoridades estÃ¡n buscando al conductor de...  \n",
       "1  los andenes son para los peatones reclama enfÃ¡...  \n",
       "2  a las  de la noche me habÃ­a quedado de encontr...  \n",
       "3  atravesados eso es lo que se les pasa por la c...  \n",
       "4  â€œestamos proponiendo la figura de un contrato ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de los datos: (13738, 7)\n"
     ]
    }
   ],
   "source": [
    "# FunciÃ³n para preprocesar texto\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Esta funciÃ³n realiza el preprocesamiento del texto.\n",
    "    1. Convierte el texto a minÃºsculas.\n",
    "    2. Elimina la puntuaciÃ³n.\n",
    "    3. Elimina los nÃºmeros.\n",
    "    4. Elimina los espacios en blanco adicionales.\n",
    "\n",
    "    ParÃ¡metros:\n",
    "    text (str): El texto original.\n",
    "\n",
    "    Retorna:\n",
    "    str: El texto preprocesado.\n",
    "    \"\"\"\n",
    "    # Convertir a minÃºsculas\n",
    "    text = text.lower()\n",
    "    # Eliminar puntuaciÃ³n\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Eliminar nÃºmeros\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Eliminar espacios en blanco adicionales\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# Aplicar preprocesamiento al contenido\n",
    "## Deben eliminarse los valores nulos antes de aplicar el preprocesamiento\n",
    "data = data.dropna(subset=['contenido'])\n",
    "\n",
    "# Aplicar preprocesamiento al contenido\n",
    "data['contenido_preprocesado'] = data['contenido'].apply(preprocess_text)\n",
    "\n",
    "# Mostrar una vista previa de los datos preprocesados\n",
    "display(data[['contenido', 'contenido_preprocesado']].head())\n",
    "\n",
    "# Dimensiones de los datos\n",
    "\n",
    "print(f'Dimensiones de los datos: {data.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9d6948",
   "metadata": {},
   "source": [
    "## Paso 2: TokenizaciÃ³n\n",
    "\n",
    "En este paso, convertiremos el texto preprocesado en una lista de palabras individuales utilizando la tokenizaciÃ³n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df47b88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contenido_preprocesado</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>las autoridades estÃ¡n buscando al conductor de...</td>\n",
       "      <td>[las, autoridades, estÃ¡n, buscando, al, conduc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>los andenes son para los peatones reclama enfÃ¡...</td>\n",
       "      <td>[los, andenes, son, para, los, peatones, recla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a las  de la noche me habÃ­a quedado de encontr...</td>\n",
       "      <td>[a, las, de, la, noche, me, habÃ­a, quedado, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>atravesados eso es lo que se les pasa por la c...</td>\n",
       "      <td>[atravesados, eso, es, lo, que, se, les, pasa,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>â€œestamos proponiendo la figura de un contrato ...</td>\n",
       "      <td>[â€œ, estamos, proponiendo, la, figura, de, un, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              contenido_preprocesado  \\\n",
       "0  las autoridades estÃ¡n buscando al conductor de...   \n",
       "1  los andenes son para los peatones reclama enfÃ¡...   \n",
       "2  a las  de la noche me habÃ­a quedado de encontr...   \n",
       "3  atravesados eso es lo que se les pasa por la c...   \n",
       "4  â€œestamos proponiendo la figura de un contrato ...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [las, autoridades, estÃ¡n, buscando, al, conduc...  \n",
       "1  [los, andenes, son, para, los, peatones, recla...  \n",
       "2  [a, las, de, la, noche, me, habÃ­a, quedado, de...  \n",
       "3  [atravesados, eso, es, lo, que, se, les, pasa,...  \n",
       "4  [â€œ, estamos, proponiendo, la, figura, de, un, ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TokenizaciÃ³n\n",
    "data['tokens'] = data['contenido_preprocesado'].apply(word_tokenize)\n",
    "\n",
    "# Mostrar una vista previa de los tokens\n",
    "data[['contenido_preprocesado', 'tokens']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de35d9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenido preprocesado:  las autoridades estÃ¡n buscando al conductor de una moto que le lanzÃ³ el casco a carlos alberto carmona operador de grÃºa de la empresa segrup  quien perdiÃ³ por una hora el conocimiento tras la agresiÃ³n en un video quedÃ³ registrado el momento en el que tanto el trabajador de la empresa como el motociclista se encuentran discutiendo cerca de la avenida villavicencio con gaitÃ¡n cortÃ©s en el acalorado encuentro verbal ambos amagan con golpearse con los objetos que tienen en sus manos entonces el conductor de la moto arroja su casco contra el operador el hombre recibe el impacto en su cara por lo que s e desgonza y en la caÃ­da se golpea la cabeza con la grÃºa que conduce  el agredido perdiÃ³ el conocimiento por cerca de una hora en ese instante el agresor se retira caminando del lugar y en repetidas ocasiones mira para atrÃ¡s en donde estÃ¡ el operador en el suelo luego su compaÃ±ero agarra la moto y huye del lugar y a pocos metros recoge al agresor las autoridades buscan al hombre que conducÃ­a la moto jto c marca pulsar color verde para que responda por la agresiÃ³n que le generÃ³ al trabajador de  aÃ±os de edad hacias las  de la maÃ±ana de este sÃ¡bado la secretarÃ­a de movilidad a travÃ©s de su cuenta de twitter rechazÃ³ este hecho mientras que la empresa operadora instaurarÃ¡ una denuncia penal por este hecho para que se realice una investigaciÃ³n bogotÃ¡ valle del cauca  pm se han recogido cerca de  mil mercados en donatÃ³n valle solidario la meta es llegar a  mil mercados personas del comÃºn y empresas se  coronavirus en colombia  pm cuarentena en medellÃ­n el diario de lo que pasa en la ciudad el miÃ©rcoles  de marzo comenzÃ³ el aislamiento obligatorio para evita  gabriel garcÃ­a mÃ¡rquez  pm falleciÃ³ el mago dÃ¡vila primer linotipista que tuvo garcÃ­a mÃ¡rquez barranquilla  pm alias el satÃ¡nico busca la libertad por vencimiento de tÃ©rminos santander  pm hombre muriÃ³ en un parque sin saber que estaba contagiado de covid\n",
      "Tokens:  ['las', 'autoridades', 'estÃ¡n', 'buscando', 'al', 'conductor', 'de', 'una', 'moto', 'que', 'le', 'lanzÃ³', 'el', 'casco', 'a', 'carlos', 'alberto', 'carmona', 'operador', 'de', 'grÃºa', 'de', 'la', 'empresa', 'segrup', 'quien', 'perdiÃ³', 'por', 'una', 'hora', 'el', 'conocimiento', 'tras', 'la', 'agresiÃ³n', 'en', 'un', 'video', 'quedÃ³', 'registrado', 'el', 'momento', 'en', 'el', 'que', 'tanto', 'el', 'trabajador', 'de', 'la', 'empresa', 'como', 'el', 'motociclista', 'se', 'encuentran', 'discutiendo', 'cerca', 'de', 'la', 'avenida', 'villavicencio', 'con', 'gaitÃ¡n', 'cortÃ©s', 'en', 'el', 'acalorado', 'encuentro', 'verbal', 'ambos', 'amagan', 'con', 'golpearse', 'con', 'los', 'objetos', 'que', 'tienen', 'en', 'sus', 'manos', 'entonces', 'el', 'conductor', 'de', 'la', 'moto', 'arroja', 'su', 'casco', 'contra', 'el', 'operador', 'el', 'hombre', 'recibe', 'el', 'impacto', 'en', 'su', 'cara', 'por', 'lo', 'que', 's', 'e', 'desgonza', 'y', 'en', 'la', 'caÃ­da', 'se', 'golpea', 'la', 'cabeza', 'con', 'la', 'grÃºa', 'que', 'conduce', 'el', 'agredido', 'perdiÃ³', 'el', 'conocimiento', 'por', 'cerca', 'de', 'una', 'hora', 'en', 'ese', 'instante', 'el', 'agresor', 'se', 'retira', 'caminando', 'del', 'lugar', 'y', 'en', 'repetidas', 'ocasiones', 'mira', 'para', 'atrÃ¡s', 'en', 'donde', 'estÃ¡', 'el', 'operador', 'en', 'el', 'suelo', 'luego', 'su', 'compaÃ±ero', 'agarra', 'la', 'moto', 'y', 'huye', 'del', 'lugar', 'y', 'a', 'pocos', 'metros', 'recoge', 'al', 'agresor', 'las', 'autoridades', 'buscan', 'al', 'hombre', 'que', 'conducÃ­a', 'la', 'moto', 'jto', 'c', 'marca', 'pulsar', 'color', 'verde', 'para', 'que', 'responda', 'por', 'la', 'agresiÃ³n', 'que', 'le', 'generÃ³', 'al', 'trabajador', 'de', 'aÃ±os', 'de', 'edad', 'hacias', 'las', 'de', 'la', 'maÃ±ana', 'de', 'este', 'sÃ¡bado', 'la', 'secretarÃ­a', 'de', 'movilidad', 'a', 'travÃ©s', 'de', 'su', 'cuenta', 'de', 'twitter', 'rechazÃ³', 'este', 'hecho', 'mientras', 'que', 'la', 'empresa', 'operadora', 'instaurarÃ¡', 'una', 'denuncia', 'penal', 'por', 'este', 'hecho', 'para', 'que', 'se', 'realice', 'una', 'investigaciÃ³n', 'bogotÃ¡', 'valle', 'del', 'cauca', 'pm', 'se', 'han', 'recogido', 'cerca', 'de', 'mil', 'mercados', 'en', 'donatÃ³n', 'valle', 'solidario', 'la', 'meta', 'es', 'llegar', 'a', 'mil', 'mercados', 'personas', 'del', 'comÃºn', 'y', 'empresas', 'se', 'coronavirus', 'en', 'colombia', 'pm', 'cuarentena', 'en', 'medellÃ­n', 'el', 'diario', 'de', 'lo', 'que', 'pasa', 'en', 'la', 'ciudad', 'el', 'miÃ©rcoles', 'de', 'marzo', 'comenzÃ³', 'el', 'aislamiento', 'obligatorio', 'para', 'evita', 'gabriel', 'garcÃ­a', 'mÃ¡rquez', 'pm', 'falleciÃ³', 'el', 'mago', 'dÃ¡vila', 'primer', 'linotipista', 'que', 'tuvo', 'garcÃ­a', 'mÃ¡rquez', 'barranquilla', 'pm', 'alias', 'el', 'satÃ¡nico', 'busca', 'la', 'libertad', 'por', 'vencimiento', 'de', 'tÃ©rminos', 'santander', 'pm', 'hombre', 'muriÃ³', 'en', 'un', 'parque', 'sin', 'saber', 'que', 'estaba', 'contagiado', 'de', 'covid']\n"
     ]
    }
   ],
   "source": [
    "## Revise los tokens para asegurarse de que el texto se haya tokenizado correctamente\n",
    "\n",
    "print(\"Contenido preprocesado: \", data['contenido_preprocesado'][0])\n",
    "print(\"Tokens: \", data['tokens'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb297fe5",
   "metadata": {},
   "source": [
    "## Paso 3: EliminaciÃ³n de Stop Words\n",
    "\n",
    "En este paso, eliminaremos las stop words de los tokens generados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e17e5bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_sin_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[las, autoridades, estÃ¡n, buscando, al, conduc...</td>\n",
       "      <td>[autoridades, buscando, conductor, moto, lanzÃ³...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[los, andenes, son, para, los, peatones, recla...</td>\n",
       "      <td>[andenes, peatones, reclama, enfÃ¡tica, carmenz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[a, las, de, la, noche, me, habÃ­a, quedado, de...</td>\n",
       "      <td>[noche, quedado, encontrar, boris, siempre, si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[atravesados, eso, es, lo, que, se, les, pasa,...</td>\n",
       "      <td>[atravesados, pasa, cabeza, residentes, transe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[â€œ, estamos, proponiendo, la, figura, de, un, ...</td>\n",
       "      <td>[â€œ, proponiendo, figura, contrato, civil, uniÃ³...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [las, autoridades, estÃ¡n, buscando, al, conduc...   \n",
       "1  [los, andenes, son, para, los, peatones, recla...   \n",
       "2  [a, las, de, la, noche, me, habÃ­a, quedado, de...   \n",
       "3  [atravesados, eso, es, lo, que, se, les, pasa,...   \n",
       "4  [â€œ, estamos, proponiendo, la, figura, de, un, ...   \n",
       "\n",
       "                                tokens_sin_stopwords  \n",
       "0  [autoridades, buscando, conductor, moto, lanzÃ³...  \n",
       "1  [andenes, peatones, reclama, enfÃ¡tica, carmenz...  \n",
       "2  [noche, quedado, encontrar, boris, siempre, si...  \n",
       "3  [atravesados, pasa, cabeza, residentes, transe...  \n",
       "4  [â€œ, proponiendo, figura, contrato, civil, uniÃ³...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminar stop words\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "data['tokens_sin_stopwords'] = data['tokens'].apply(lambda tokens: [word for word in tokens if word not in stop_words])\n",
    "\n",
    "# Mostrar una vista previa de los tokens sin stop words\n",
    "data[['tokens', 'tokens_sin_stopwords']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b574ffa",
   "metadata": {},
   "source": [
    "## Paso 4: CÃ¡lculo de TF-IDF\n",
    "\n",
    "En este paso, calcularemos la representaciÃ³n TF-IDF de los textos preprocesados. TF-IDF (Term Frequency-Inverse Document Frequency) es una tÃ©cnica que pondera la importancia de una palabra en un documento en relaciÃ³n con un corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc795571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaacpt</th>\n",
       "      <th>aaah</th>\n",
       "      <th>aaas</th>\n",
       "      <th>aac</th>\n",
       "      <th>aacsb</th>\n",
       "      <th>aacta</th>\n",
       "      <th>aademÃ¡s</th>\n",
       "      <th>aage</th>\n",
       "      <th>...</th>\n",
       "      <th>ğ‘“ğ‘–ğ‘—ğ‘œğ‘ </th>\n",
       "      <th>ğ‘™ğ‘</th>\n",
       "      <th>ğ‘šğ‘ğ‘Ÿğ‘ğ‘œ</th>\n",
       "      <th>ğ‘šğ‘–ğ‘’ğ‘šğ‘ğ‘Ÿğ‘œğ‘ </th>\n",
       "      <th>ğ‘šğ‘¢ğ‘’ğ‘ ğ‘¡ğ‘Ÿğ‘</th>\n",
       "      <th>ğ‘ğ‘ğ‘’ğ‘™ğ‘¢ğ‘™ğ‘ğ‘Ÿ</th>\n",
       "      <th>ğ‘ğ‘’ğ‘Ÿğ‘ ğ‘œğ‘›ğ‘</th>\n",
       "      <th>ğ‘ğ‘’ğ‘Ÿğ‘ ğ‘œğ‘›ğ‘ğ‘ </th>\n",
       "      <th>ğ‘ğ‘“ğ‘–ğ‘—ğ‘œ</th>\n",
       "      <th>ğ‘ğ‘–</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 119615 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aaa  aaacpt  aaah  aaas  aac  aacsb  aacta  aademÃ¡s  aage  ...  ğ‘“ğ‘–ğ‘—ğ‘œğ‘   \\\n",
       "0  0.0  0.0     0.0   0.0   0.0  0.0    0.0    0.0      0.0   0.0  ...    0.0   \n",
       "1  0.0  0.0     0.0   0.0   0.0  0.0    0.0    0.0      0.0   0.0  ...    0.0   \n",
       "2  0.0  0.0     0.0   0.0   0.0  0.0    0.0    0.0      0.0   0.0  ...    0.0   \n",
       "3  0.0  0.0     0.0   0.0   0.0  0.0    0.0    0.0      0.0   0.0  ...    0.0   \n",
       "4  0.0  0.0     0.0   0.0   0.0  0.0    0.0    0.0      0.0   0.0  ...    0.0   \n",
       "\n",
       "    ğ‘™ğ‘  ğ‘šğ‘ğ‘Ÿğ‘ğ‘œ  ğ‘šğ‘–ğ‘’ğ‘šğ‘ğ‘Ÿğ‘œğ‘   ğ‘šğ‘¢ğ‘’ğ‘ ğ‘¡ğ‘Ÿğ‘  ğ‘ğ‘ğ‘’ğ‘™ğ‘¢ğ‘™ğ‘ğ‘Ÿ  ğ‘ğ‘’ğ‘Ÿğ‘ ğ‘œğ‘›ğ‘  ğ‘ğ‘’ğ‘Ÿğ‘ ğ‘œğ‘›ğ‘ğ‘   ğ‘ğ‘“ğ‘–ğ‘—ğ‘œ   ğ‘ğ‘–  \n",
       "0  0.0    0.0       0.0      0.0       0.0      0.0       0.0    0.0  0.0  \n",
       "1  0.0    0.0       0.0      0.0       0.0      0.0       0.0    0.0  0.0  \n",
       "2  0.0    0.0       0.0      0.0       0.0      0.0       0.0    0.0  0.0  \n",
       "3  0.0    0.0       0.0      0.0       0.0      0.0       0.0    0.0  0.0  \n",
       "4  0.0    0.0       0.0      0.0       0.0      0.0       0.0    0.0  0.0  \n",
       "\n",
       "[5 rows x 119615 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unir los tokens en una sola cadena de texto para cada documento\n",
    "data['texto_sin_stopwords'] = data['tokens_sin_stopwords'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "# Calcular TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data['texto_sin_stopwords'])\n",
    "\n",
    "# Convertir la matriz TF-IDF a un DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Mostrar una vista previa de la matriz TF-IDF\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46975efd",
   "metadata": {},
   "source": [
    "### Â¿QuÃ© ganamos con TF-IDF?\n",
    "\n",
    "- **Frecuencia de tÃ©rmino (TF)**: Mide la frecuencia de una palabra en un documento. Si una palabra aparece muchas veces en un documento, es probable que sea importante para ese documento.\n",
    "- **Frecuencia inversa de documento (IDF)**: Mide la rareza de una palabra en un corpus. Si una palabra es comÃºn en muchos documentos, es menos informativa que una palabra rara.\n",
    "\n",
    "La fÃ³rmula de TF-IDF es:\n",
    "\n",
    "$$ \\text{TF-IDF}(t, d) = \\text{TF}(t, d) \\times \\text{IDF}(t) $$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- $\\text{TF}(t, d)$ es la frecuencia de la palabra $t$ en el documento $d$.\n",
    "- $\\text{IDF}(t)$ es la frecuencia inversa de documento de la palabra $t$ en el corpus.\n",
    "\n",
    "pero, que fue lo que hicimos, en resumen, con TF-IDF, convertimos el texto en vectores numÃ©ricos que representan la importancia de las palabras en el texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "529812c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En este ejemplo particular tomamos el contenido:\n",
      "\n",
      "las autoridades estÃ¡n buscando al conductor de una moto que le lanzÃ³ el casco a\n",
      "carlos alberto carmona operador de grÃºa de la empresa segrup quien perdiÃ³ por una hora\n",
      "el conocimiento tras la agresiÃ³n en un video quedÃ³ registrado el momento en el que\n",
      "tanto el trabajador de la empresa como el motociclista se encuentran discutiendo cerca de la\n",
      "avenida villavicencio con gaitÃ¡n cortÃ©s en el acalorado encuentro verbal ambos amagan con golpearse con\n",
      "los objetos que tienen en sus manos entonces el conductor de la moto arroja su\n",
      "casco contra el operador el hombre recibe el impacto en su cara por lo que\n",
      "s e desgonza y en la caÃ­da se golpea la cabeza con la grÃºa que\n",
      "conduce el agredido perdiÃ³ el conocimiento por cerca de una hora en ese instante el\n",
      "agresor se retira caminando del lugar y en repetidas ocasiones mira para atrÃ¡s en donde\n",
      "estÃ¡ el operador en el suelo luego su compaÃ±ero agarra la moto y huye del\n",
      "lugar y a pocos metros recoge al agresor las autoridades buscan al hombre que conducÃ­a\n",
      "la moto jto c marca pulsar color verde para que responda por la agresiÃ³n que\n",
      "le generÃ³ al trabajador de aÃ±os de edad hacias las de la maÃ±ana de este\n",
      "sÃ¡bado la secretarÃ­a de movilidad a travÃ©s de su cuenta de twitter rechazÃ³ este hecho\n",
      "mientras que la empresa operadora instaurarÃ¡ una denuncia penal por este hecho para que se\n",
      "realice una investigaciÃ³n bogotÃ¡ valle del cauca pm se han recogido cerca de mil mercados\n",
      "en donatÃ³n valle solidario la meta es llegar a mil mercados personas del comÃºn y\n",
      "empresas se coronavirus en colombia pm cuarentena en medellÃ­n el diario de lo que pasa\n",
      "en la ciudad el miÃ©rcoles de marzo comenzÃ³ el aislamiento obligatorio para evita gabriel garcÃ­a\n",
      "mÃ¡rquez pm falleciÃ³ el mago dÃ¡vila primer linotipista que tuvo garcÃ­a mÃ¡rquez barranquilla pm alias\n",
      "el satÃ¡nico busca la libertad por vencimiento de tÃ©rminos santander pm hombre muriÃ³ en un\n",
      "parque sin saber que estaba contagiado de covid \n",
      "\n",
      "Y lo convertimos en un vector TF-IDF de 119615 dimensiones:\n",
      "\n",
      "aa          0.0\n",
      "aaa         0.0\n",
      "aaacpt      0.0\n",
      "aaah        0.0\n",
      "aaas        0.0\n",
      "           ... \n",
      "ğ‘ğ‘ğ‘’ğ‘™ğ‘¢ğ‘™ğ‘ğ‘Ÿ    0.0\n",
      "ğ‘ğ‘’ğ‘Ÿğ‘ ğ‘œğ‘›ğ‘     0.0\n",
      "ğ‘ğ‘’ğ‘Ÿğ‘ ğ‘œğ‘›ğ‘ğ‘     0.0\n",
      "ğ‘ğ‘“ğ‘–ğ‘—ğ‘œ       0.0\n",
      "ğ‘ğ‘–          0.0\n",
      "Name: 0, Length: 119615, dtype: float64.\n",
      "\n",
      "\n",
      "Acabamos de convertir un documento de texto en un vector numÃ©rico que puede ser\n",
      "utilizado en algoritmos de aprendizaje automÃ¡tico. Ese vector representa la importancia \n",
      "de cada palabra en el documento original y nos permite usar por ejemplo:\n",
      "\n",
      "- ACP para reducir la dimensionalidad del vector.\n",
      "- Clustering para agrupar documentos similares.\n",
      "- ClasificaciÃ³n para predecir la categorÃ­a de un documento.\n",
      "- RecuperaciÃ³n de informaciÃ³n para encontrar documentos similares.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# InformaciÃ³n adicional\n",
    "lista_contenido= data['contenido_preprocesado'][0].split()\n",
    "# Incluimos \\n cada 15 palabras para mejorar la legibilidad\n",
    "\n",
    "lista_contenido= [f\"{word} \" if (i+1)%15!=0 else f\"{word}\\n\" for i, word in enumerate(lista_contenido)]\n",
    "\n",
    "## Ahora convertimos la lista en un string\n",
    "\n",
    "contenido= ''.join(lista_contenido)\n",
    "\n",
    "text_info= f\"\"\"En este ejemplo particular tomamos el contenido:\n",
    "\n",
    "{contenido}\n",
    "\n",
    "Y lo convertimos en un vector TF-IDF de {tfidf_df.shape[1]} dimensiones:\n",
    "\n",
    "{tfidf_df.iloc[0]}.\n",
    "\n",
    "\n",
    "Acabamos de convertir un documento de texto en un vector numÃ©rico que puede ser\n",
    "utilizado en algoritmos de aprendizaje automÃ¡tico. Ese vector representa la importancia \n",
    "de cada palabra en el documento original y nos permite usar por ejemplo:\n",
    "\n",
    "- ACP para reducir la dimensionalidad del vector.\n",
    "- Clustering para agrupar documentos similares.\n",
    "- ClasificaciÃ³n para predecir la categorÃ­a de un documento.\n",
    "- RecuperaciÃ³n de informaciÃ³n para encontrar documentos similares.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(text_info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61e4cb2",
   "metadata": {},
   "source": [
    "## Paso 5: GeneraciÃ³n de Embeddings de Palabras con Word2Vec\n",
    "\n",
    "En este paso, utilizaremos el modelo Word2Vec para generar embeddings de palabras. Los embeddings de palabras son representaciones vectoriales densas que capturan el significado semÃ¡ntico de las palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebcd5b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding de la palabra \"noticia\":\n",
      "[-0.998568   -0.39457625 -0.9017437  -0.052319   -1.6498146  -1.6450179\n",
      " -0.3573322   1.6330923  -0.9405224  -0.86355436  0.5012254   0.57607496\n",
      " -0.12113702 -0.6868152   0.0543102  -0.06434404 -0.22088476  0.6956336\n",
      " -0.32347533 -0.5418966   0.42477214  0.4795706  -0.41780907 -0.16724594\n",
      " -0.48869595  0.6827344  -1.5535585  -0.74637336  0.23836274  0.2351681\n",
      " -0.44996387  1.2937291  -0.6090053   0.13814652 -0.2040972  -0.20179765\n",
      " -0.60217685  0.70654064 -0.10101053 -0.8398079  -0.32902965 -0.40184355\n",
      "  0.41803554 -0.42580485 -0.03347557 -0.08226635  0.8613035   0.7317195\n",
      "  0.4908356  -0.3226947   1.1456008   0.10811742  0.64416516 -0.54286283\n",
      " -0.90631723 -0.3300786   0.95458907 -0.4755654   1.0743126   1.2178994\n",
      "  0.9697795  -0.16401732 -0.33175012 -0.06415146  0.6125741   1.3644797\n",
      " -0.69736284  0.19250447 -0.1182953  -0.16355817 -0.69536984 -0.4639998\n",
      " -0.33235246 -0.34871352 -0.2577953   0.8260709   0.4483591   0.57320297\n",
      "  0.4713225  -0.68326366 -0.9376265   0.37564874 -0.01236518  0.2791497\n",
      "  0.47369328 -0.43062767 -0.44073072 -0.20241953  1.075498    0.7241306\n",
      " -0.06447753 -0.75106233 -1.2403716   2.2773564   1.0541815   0.9268482\n",
      "  0.99176824 -1.1431247   0.34645742  0.7096243 ]\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo Word2Vec\n",
    "word2vec_model = Word2Vec(sentences=data['tokens_sin_stopwords'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Obtener los embeddings de una palabra ejemplo\n",
    "word_example = 'noticia'\n",
    "if word_example in word2vec_model.wv:\n",
    "    embedding_example = word2vec_model.wv[word_example]\n",
    "    print(f'Embedding de la palabra \"{word_example}\":\\n{embedding_example}')\n",
    "else:\n",
    "    print(f'La palabra \"{word_example}\" no estÃ¡ en el vocabulario del modelo Word2Vec.')\n",
    "\n",
    "# Guardar el modelo Word2Vec\n",
    "word2vec_model.save(\"../../Datos/Embeddings/word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23b2b83",
   "metadata": {},
   "source": [
    "## Guardar Resultados\n",
    "\n",
    "Finalmente, guardaremos los resultados preprocesados en un archivo CSV para su posterior uso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07db4e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los resultados preprocesados\n",
    "data.to_csv('../../Datos/Datos Preprocesados/Noticias_preprocesadas.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_proyecto_final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
